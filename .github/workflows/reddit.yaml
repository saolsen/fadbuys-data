on:
  schedule:
    - cron: "0 */6 * * *"
  push:
    branches:
      - main

jobs:
  pull_reddit_data:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        list: [hot, new, top]
        subreddit:
          [books, fantasy, literature, yalit, weirdlit, PrintSF, DystopianBooks]
    steps:
      - uses: actions/setup-python@v4
        with:
          python-version: "3.11"
      - name: Install bdfr
        run: "pip install bdfr"
      - name: Download 200 ${{ matrix.list }} posts from ${{ matrix.subreddit }}
        run: |
          timeout 1m bdfr archive ./archive/${{ matrix.list }} --subreddit ${{ matrix.subreddit }} --sort ${{ matrix.list }} --file-scheme "{POSTID}" -L 200 || code=$?; if [[ $code -ne 124 && $code -ne 0 ]]; then exit $code; fi
      - name: Upload posts
        uses: actions/upload-artifact@v3
        with:
          name: archive
          path: archive

  save_results:
    runs-on: ubuntu-latest
    needs: [pull_reddit_data]
    steps:
      - uses: actions/checkout@v2
      - name: install duckdb
        run: |
          wget https://github.com/duckdb/duckdb/releases/download/v0.6.1/duckdb_cli-linux-amd64.zip
          unzip -o duckdb_cli-linux-amd64.zip
          chmod 774 ./duckdb

      - name: download the results
        uses: actions/download-artifact@v3
        with:
          name: archive
          path: archive

      - uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: install deps
        run: pip install -r requirements.txt

      - name: process files
        run: python process_dump.py

      - name: export database
        run: echo "EXPORT DATABASE 'data' (FORMAT PARQUET);" | ./duckdb fadbuys-data.db

      - name: Commit data
        uses: EndBug/add-and-commit@v5
        with:
          add: "."
          author_name: "fadbuys"
          message: "Sync ${{github.run_number}}"
        env:
          GITHUB_TOKEN: ${{secrets.GITHUB_TOKEN}}

      - name: complete
        run: curl https://nosnch.in/823740e37e
